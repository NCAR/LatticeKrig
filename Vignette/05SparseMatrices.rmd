# Using Sparse Matrices

One unique feature of LatticeKrig is the assumption that the covariance function and basis function have compact support, meaning they equal 0 everywhere outside a certain region. We use radially symmetric basis functions, so the region where the functions have nonzero values is a circle (or sphere in 3D or interval in 1D). This means that many of the pairs of basis functions or data locations will be too far apart to fit in the region, so the covariance between the two points --- or the basis function from one point evaluated at the other point, since the basis function and covariance function are the same --- will be 0. This leads to covariance matrices and basis matrices where the majority of the entries are 0, which is called a sparse matrix. Computing with sparse matrices can be much faster than computing with normal matrices, since the computer can save space by only tracking the location and values of the nonzero entries, and algorithms can skip all of the 0 entries. This optimization makes sparse matrix computations on large data sets orders of magnitude faster than the traditional corresponding computations.

In this package, we use the \ttt{spam} package for sparse matrices. This package has built-in methods for storing, multiplying, and solving sparse matrices, as well as finding their Cholesky decomposition, all of which are used heavily in LatticeKrig. The Cholesky decomposition of a matrix $A$ finds the lower triangular matrix $L$ such that $L L^T = A$. This is heavily used in LatticeKrig because it is significantly easier to solve a triangular system than a normal system ($\mathcal O(n^2)$ v.s. $\mathcal O(n^3)$), which combines with the optimization of using sparse matrices to make our calculations practical on very large data sets. 

In the following code, we will time how long it takes to compute the Cholesky decomposition of sparse matrices with and without taking advantage of the sparsity. We will consider $100 \times 100$, $300 \times 300$, $1000 \times 1000$, and $3000 \times 3000$ matrices. For each size, we will first do the Cholesky decomposition on the full matrix representation, then on the sparse representation.
```{r SparseCholComparison}
for(N in c(100, 300, 1000, 3000)) {
  FMat <- LKDiag(c(-1, 5, -1), N)
  SMat <- as.spam(FMat)
  cat("Matrix size: ", N, "\n")
  cat("Full Matrix:\t")
  startTime <- Sys.time()
  FChol <- chol(FMat)
  stopTime <- Sys.time()
  delta <- stopTime - startTime
  print(delta)
  
  cat("Sparse Matrix:\t")
  startTime <- Sys.time()
  SChol <- chol(SMat)
  stopTime <- Sys.time()
  delta <- stopTime - startTime
  print(delta)
  cat("\n")
}
```