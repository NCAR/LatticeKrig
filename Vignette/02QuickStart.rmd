# Quick Start Guide

In this section, we will lay out the bare essentials of the package as a quick overview. To fit a surface and interpolate data using \ttt{LatticeKrig}, the only required arguments are, naturally, the measurement locations (formatted in a matrix where each row is one location) and measurement values. However, we highly recommend using some of the optional parameters to customize the model to your specific data problem - several ways to do this are illustrated in this vignette. Calling the \ttt{LatticeKrig} function and passing in the locations and values will produce an \ttt{LKrig} object that contains all the information needed to predict the variable at any location. 

For a simple, 1-dimensional example, we will take our locations to be 50 randomly spaced points on the interval $[-6, 6]$, and our variable measurements to be the values of $\sin(x)$ at these locations. The goal of our kriging fit is to estimate this smooth curve from the observations.

## Fitting the model in one dimension

```{r QuickStart1D}
set.seed(223)
locations <- runif(50, min=-6, max=6)
locations <- as.matrix(locations)
observations <- sin(locations) + rnorm(50, sd = 1e-1)
kFit1D <- LatticeKrig(locations, observations)
```

Now we will print out the \ttt{LKrig} object: this list features the data's estimated covariance scale \ttt{rho} and estimated standard measurement error \ttt{sigma}, and many basis function settings: the type of basis function, how distance is measured, and the number and spacing of basis functions. In this example, all of this information is determined by \ttt{LatticeKrig} from the defaults, but can be changed with optional parameters.

```{r QuickStart1DPrintout}
print(kFit1D)
```

##Plotting the results

Now, we'll make a plot of the original 50 data points and the true function ($\sin(x)$) and the \ttt{LatticeKrig} fit at 200 equally spaced points to compare them.
```{r QuickStart1DPlot}
xGrid <- seq(-2*pi, 2*pi, len=200)
prediction <- predict(kFit1D, xGrid)
plot(locations, observations, main="1-Dimensional LatticeKrig Example", 
     xlab="Location", ylab="Measured Value")
lines(xGrid, sin(xGrid), col='blue')
lines(xGrid, prediction, col='red', lty=2, lwd=2)
```

For this example, the fitted curve (in red) matches the true function (in blue) rather closely. This next plot adds a collection of simulations based on the fitted curve; the simulations get farther apart, meaning the standard error gets larger, where there aren't many data points and especially at the edges of the region. These simulations are easier to compute than the standard error, so they are used to estimate the standard error of a model in LatticeKrig.

```{r QuickStart1DResidualPlot}
uncertainty <- LKrig.sim.conditional(kFit1D, x.grid = as.matrix(xGrid), M=5)
matplot(uncertainty$g.draw, type="l", x = seq(-6,6, length.out = 200),
        main = "Simulated Curves", xlab = "Location", ylab = "Measured Value")
lines(xGrid, sin(xGrid), col='blue', lwd = 3)
lines(xGrid, prediction, col='red', lty=2, lwd=3)
```

## Fitting the model in two dimensions

For another, more practical example, we will predict the average spring temperature for locations throughout Colorado. Using the data set \ttt{COmonthlyMet}, we can make a surface showing our predictions over a range of longitudes and latitudes, and use the \ttt{US} function to draw in the USA state borders to show where Colorado is. Notice that \ttt{LatticeKrig} will automatically discard any data points with missing values (NAs) if needed.

```{r QuickStart2D}
data(COmonthlyMet)
locations <- CO.loc
observations <- CO.tmean.MAM.climate
kFitWeather <- LatticeKrig(locations, observations)
surface(kFitWeather, main = "2-Dimensional LatticeKrig Example",
        xlab="Longitude", ylab="Latitude")
US(add=TRUE, col='black', lwd=4)
```

This plot is useful, but we can do better. We can see that the coldest temperatures are in the Rocky Mountains, which is not surprising. Thus, we might expect that we will get a more accurate fit by having \ttt{LatticeKrig} account for the elevation at each location as well. Another way we can improve the plot is by increasing its resolution - the current image is somewhat pixelated. The \ttt{surface} function will evaluate the surface at more points if we increase the \ttt{nx} and \ttt{ny} arguments: setting \ttt{nx=200, ny=150} will produce a grid of 30,000 points, which will take longer to compute but produces a nicer looking, more detailed plot. Finally, we can also have \ttt{surface} extend the evaluation all the way to the corners of the window by using the \ttt{extrap} argument; by default it doesn't extrapolate outside of the existing data, since the error often increases dramatically when predicting outside of the given data. However, extending the plot to the corners will make it look nicer. For the sake of example, we will also change the color scale in the image by setting the \ttt{col} parameter.

```{r QuickStart2DImproved}
data(COmonthlyMet)
locations <- CO.loc
observations <- CO.tmean.MAM.climate
elevations <- CO.elev
kFitWeather <- LatticeKrig(locations, observations, Z=cbind(elevations))
# look at the help file in fields for information on the grid.list format
prediction <- predictSurface(kFitWeather, grid.list = CO.Grid, ZGrid = CO.elevGrid,
                             nx = 200, ny = 150, extrap = TRUE)
surface(prediction, main = "Improved 2-Dimensional LatticeKrig Example", 
        xlab="Longitude", ylab="Latitude", col=larry.colors())
US(add=TRUE, col='black', lwd=4)
```

This surface is so rough because it accounts for elevation; we can see that the plot is fairly smooth in the eastern half of the state, and extremely rough in the mountains. 

Finally, it is important to note some potential issues that \ttt{LatticeKrig} calculations won't catch. Because \ttt{LatticeKrig} estimates some parameters of the data, the model could be a poor fit if the estimates aren't reasonable. The \ttt{LatticeKrig} model also approximates a thin plate spline by default, which may not be a good fit for a given problem. Finally, as with other curve fitting techniques, you should examine the residuals of the model for any patterns or features that may indicate a poor fit.